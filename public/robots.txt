# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-agent: *
# Disallow: /

# Allow all crawlers
User-agent: *
Allow: /

# Sitemap location
Sitemap: https://youtupedia.com/sitemap.xml.gz

# Prevent crawling of certain paths
Disallow: /admin/
Disallow: /api/
Disallow: /internal/
Disallow: /tmp/
Disallow: /assets/
Disallow: /*.json
Disallow: /*?*
